{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Members Names\n",
        "1. Muhammad Hassan Saboor (23L-8006)\n",
        "2. Muhammad Haider Abbas  (23L-8017)\n",
        "3. Muhammad Farhan Naveed (23L-8024)"
      ],
      "metadata": {
        "id": "jab-yQytBJAo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYA5NHAEiies"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d meowmeowmeowmeowmeow/gtsrb-german-traffic-sign"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S__jCMJXioB3",
        "outputId": "5ae7ba77-accb-474b-d315-53bfb562b3a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "gtsrb-german-traffic-sign.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/gtsrb-german-traffic-sign.zip','r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "pLlTRPm3iw7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
        "X = []\n",
        "Y = []\n",
        "total_class = 43\n",
        "cur_directory = os.getcwd()"
      ],
      "metadata": {
        "id": "hEgCCr9niz_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index in range(total_class):\n",
        "    path = os.path.join(cur_directory, 'train', str(index))\n",
        "    images = os.listdir(path)\n",
        "\n",
        "    # Iterating on all the images of the index folder\n",
        "    for img in images:\n",
        "        try:\n",
        "            image = Image.open(os.path.join(path, img))\n",
        "            image = image.resize((30, 30))\n",
        "            image = np.array(image)\n",
        "            X.append(image)\n",
        "            Y.append(index)\n",
        "        except:\n",
        "            print(\"Error loading image\")\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "print(X.shape, Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pbvj8IQri6U3",
        "outputId": "4481a967-97b8-416c-e435-5dc46bf8df5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(39209, 30, 30, 3) (39209,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Shape of x_train:\", x_train.shape, \"and y_train:\", y_train.shape)\n",
        "print(\"Shape of x_test:\", x_test.shape, \"and y_test:\", y_test.shape)\n",
        "\n",
        "# One hot encoding the labels\n",
        "y_train = to_categorical(y_train, 43)\n",
        "y_test = to_categorical(y_test, 43)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9bdhcGJi910",
        "outputId": "68d5c295-a103-4e3f-bca3-cafa304c24a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x_train: (31367, 30, 30, 3) and y_train: (31367,)\n",
            "Shape of x_test: (7842, 30, 30, 3) and y_test: (7842,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Existing layers\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', input_shape=x_train.shape[1:]))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(rate=0.25))\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(rate=0.25))\n",
        "\n",
        "# Additional layer\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))  # Additional Convolutional layer\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))  # Additional MaxPooling layer\n",
        "model.add(Dropout(rate=0.25))  # Additional Dropout layer\n",
        "\n",
        "# Flatten layer and fully connected layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(rate=0.5))\n",
        "model.add(Dense(43, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "1JUWfC4hjCfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shapes - x_train:\", x_train.shape, \"y_train:\", y_train.shape)\n",
        "print(\"Shapes - x_test:\", x_test.shape, \"y_test:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9E27fPMjGVG",
        "outputId": "a0b66422-77fd-430b-b9db-6052a9f62a82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes - x_train: (31367, 30, 30, 3) y_train: (31367, 43)\n",
            "Shapes - x_test: (7842, 30, 30, 3) y_test: (7842, 43)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 25\n",
        "history = model.fit(x_train, y_train, batch_size=64, epochs=epochs, validation_data=(x_test, y_test))\n",
        "model.save('traffic_recognition.h5')"
      ],
      "metadata": {
        "id": "gZnQiWMJjJW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "y_test = pd.read_csv('Test.csv')\n",
        "labels = y_test[\"ClassId\"].values\n",
        "img_paths = y_test[\"Path\"].values\n",
        "\n",
        "test_data = []\n",
        "for path in img_paths:\n",
        "    image = Image.open(path)\n",
        "    image = image.resize((30, 30))\n",
        "    test_data.append(np.array(image))\n",
        "\n",
        "test_data = np.array(test_data)\n",
        "\n",
        "pred_probabilities = model.predict(test_data)\n",
        "pred = np.argmax(pred_probabilities, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(labels, pred))\n"
      ],
      "metadata": {
        "id": "KIuczIy1jL-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(labels, pred)\n",
        "print(\"Accuracy with the test data:\", accuracy*100)"
      ],
      "metadata": {
        "id": "nPcgl4cDkSLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate classification report and store its values\n",
        "classification_rep = classification_report(labels, pred, output_dict=True)\n",
        "precision = [classification_rep[str(i)]['precision'] for i in range(len(classification_rep) - 3)]\n",
        "recall = [classification_rep[str(i)]['recall'] for i in range(len(classification_rep) - 3)]\n",
        "f1_score = [classification_rep[str(i)]['f1-score'] for i in range(len(classification_rep) - 3)]\n",
        "class_names = [str(i) for i in range(len(classification_rep) - 3)]"
      ],
      "metadata": {
        "id": "QWJ3NcJ2k0kD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# Precision plot\n",
        "ax[0].bar(class_names, precision, color='skyblue')\n",
        "ax[0].set_xlabel('Precision')\n",
        "ax[0].set_title('Precision per Class')\n",
        "\n",
        "# Recall plot\n",
        "ax[1].bar(class_names, recall, color='lightgreen')\n",
        "ax[1].set_xlabel('Recall')\n",
        "ax[1].set_title('Recall per Class')\n",
        "\n",
        "# F1-score plot\n",
        "ax[2].bar(class_names, f1_score, color='salmon')\n",
        "ax[2].set_xlabel('F1-score')\n",
        "ax[2].set_title('F1-score per Class')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XyefjIC2nu4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# Precision plot (Line Chart)\n",
        "ax[0].plot(class_names, precision, marker='o', linestyle='-', color='skyblue')\n",
        "ax[0].set_xlabel('Classes')\n",
        "ax[0].set_ylabel('Precision')\n",
        "ax[0].set_title('Precision per Class')\n",
        "ax[0].grid(True)\n",
        "\n",
        "# Recall plot (Line Chart)\n",
        "ax[1].plot(class_names, recall, marker='o', linestyle='-', color='lightgreen')\n",
        "ax[1].set_xlabel('Classes')\n",
        "ax[1].set_ylabel('Recall')\n",
        "ax[1].set_title('Recall per Class')\n",
        "ax[1].grid(True)\n",
        "\n",
        "# F1-score plot (Line Chart)\n",
        "ax[2].plot(class_names, f1_score, marker='o', linestyle='-', color='salmon')\n",
        "ax[2].set_xlabel('Classes')\n",
        "ax[2].set_ylabel('F1-score')\n",
        "ax[2].set_title('F1-score per Class')\n",
        "ax[2].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jZRUN2PFnyMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plotting training and validation accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Plotting training and validation loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PtksVmLDn11u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model('traffic_recognition.h5')\n",
        "\n",
        "# Dictionary to label all traffic signs classes\n",
        "classes = {\n",
        "    1: 'Speed limit (20km/h)',\n",
        "    2: 'Speed limit (30km/h)',\n",
        "    3: 'Speed limit (50km/h)',\n",
        "    4: 'Speed limit (60km/h)',\n",
        "    5: 'Speed limit (70km/h)',\n",
        "    6: 'Speed limit (80km/h)',\n",
        "    7: 'End of speed limit (80km/h)',\n",
        "    8: 'Speed limit (100km/h)',\n",
        "    9: 'Speed limit (120km/h)',\n",
        "    10: 'No passing',\n",
        "    11: 'No passing veh over 3.5 tons',\n",
        "    12: 'Right-of-way at intersection',\n",
        "    13: 'Priority road',\n",
        "    14: 'Yield',\n",
        "    15: 'Stop',\n",
        "    16: 'No vehicles',\n",
        "    17: 'Veh > 3.5 tons prohibited',\n",
        "    18: 'No entry',\n",
        "    19: 'General caution',\n",
        "    20: 'Dangerous curve left',\n",
        "    21: 'Dangerous curve right',\n",
        "    22: 'Double curve',\n",
        "    23: 'Bumpy road',\n",
        "    24: 'Slippery road',\n",
        "    25: 'Road narrows on the right',\n",
        "    26: 'Road work',\n",
        "    27: 'Traffic signals',\n",
        "    28: 'Pedestrians',\n",
        "    29: 'Children crossing',\n",
        "    30: 'Bicycles crossing',\n",
        "    31: 'Beware of ice/snow',\n",
        "    32: 'Wild animals crossing',\n",
        "    33: 'End speed + passing limits',\n",
        "    34: 'Turn right ahead',\n",
        "    35: 'Turn left ahead',\n",
        "    36: 'Ahead only',\n",
        "    37: 'Go straight or right',\n",
        "    38: 'Go straight or left',\n",
        "    39: 'Keep right',\n",
        "    40: 'Keep left',\n",
        "    41: 'Roundabout mandatory',\n",
        "    42: 'End of no passing',\n",
        "    43: 'End no passing veh > 3.5 tons'\n",
        "}\n",
        "\n",
        "\n",
        "def predict_traffic_sign(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    image = image.resize((30, 30))\n",
        "    image = np.array(image)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "\n",
        "    pred_probabilities = model.predict(image)\n",
        "    pred_class = np.argmax(pred_probabilities, axis=1)[0]\n",
        "    sign = classes[pred_class + 1]\n",
        "\n",
        "    return sign\n",
        "\n",
        "# Example usage:\n",
        "image_path_to_test = 'image url'  # Replace this with the path to your test image\n",
        "predicted_sign = predict_traffic_sign(image_path_to_test)\n",
        "print(\"Predicted Traffic Sign:\", predicted_sign)"
      ],
      "metadata": {
        "id": "4201VrRRn6BJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sLFEQfrboCba"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}